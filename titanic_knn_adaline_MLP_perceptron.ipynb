{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "niciM1fhBZh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91056be2-04f5-4380-8a19-f103f80c67b4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "!pip install keras\n",
        "from numpy.linalg import inv\n",
        "from tensorflow.keras.layers import Dense\n",
        "from collections import defaultdict\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential, Model\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZLtkjGLBfmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "d67c42f4-7b54-4369-ea2d-89f39a1bc50d"
      },
      "source": [
        "train_data=pd.read_csv('train.csv')\n",
        "train_data.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8i8l7-EBfx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "720d0910-7bc6-457b-aa56-6b0ce794d015"
      },
      "source": [
        "train_data=train_data.replace(['female','male'],[0,1])\n",
        "train_data=train_data.replace(['S','C','Q'],[0,1,2])\n",
        "tarin_data=train_data.fillna(0,inplace=True)\n",
        "train_data.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare  Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500      0       0.0\n",
              "1            2         1       1  ...  71.2833    C85       1.0\n",
              "2            3         1       3  ...   7.9250      0       0.0\n",
              "3            4         1       1  ...  53.1000   C123       0.0\n",
              "4            5         0       3  ...   8.0500      0       0.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maNcFe9NBe6Q"
      },
      "source": [
        "Y_train=train_data[['Survived']]\n",
        "X_train=train_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "Y_train=np.array(Y_train)\n",
        "X_train=np.array(X_train)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SynBefa_zYtA",
        "outputId": "3c6535d4-6b50-4371-f00f-07d49107b859"
      },
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "test_data = test_data.replace(['female', 'male'], [0, 1])\n",
        "test_data = test_data.replace(['S', 'C', 'Q'], [0, 1, 2])\n",
        "test_data = test_data.fillna(0)\n",
        "X_test = test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "test = pd.read_csv('gender_submission.csv')\n",
        "Y_test = test[['Survived']]\n",
        "\n",
        "X_test.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
              "0       3    1  34.5      0      0   7.8292         2\n",
              "1       3    0  47.0      1      0   7.0000         0\n",
              "2       2    1  62.0      0      0   9.6875         2\n",
              "3       3    1  27.0      0      0   8.6625         0\n",
              "4       3    0  22.0      1      1  12.2875         0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKDRY6K9zYzi"
      },
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "                               tf.keras.layers.Dense(16,activation='relu'),\n",
        "                               tf.keras.layers.Dense(16,activation='relu'),\n",
        "                               tf.keras.layers.Dense(8,activation='relu'),\n",
        "                               tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "\n",
        "])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKoME6FMDAAH"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.mean_absolute_error,metrics=['accuracy'])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXr0dT2zZBs",
        "outputId": "802151c2-80b9-402d-9568-a5a700be86fb"
      },
      "source": [
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "output=model.fit(X_train,Y_train,epochs=200)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7) (891, 1)\n",
            "(418, 7) (418, 1)\n",
            "Epoch 1/200\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5751 - accuracy: 0.3951\n",
            "Epoch 2/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.5836\n",
            "Epoch 3/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.6936\n",
            "Epoch 4/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.6970\n",
            "Epoch 5/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.6981\n",
            "Epoch 6/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.7015\n",
            "Epoch 7/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.7003\n",
            "Epoch 8/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.7015\n",
            "Epoch 9/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.7071\n",
            "Epoch 10/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.7138\n",
            "Epoch 11/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.7048\n",
            "Epoch 12/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.7104\n",
            "Epoch 13/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.7082\n",
            "Epoch 14/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.7059\n",
            "Epoch 15/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2956 - accuracy: 0.7138\n",
            "Epoch 16/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.7104\n",
            "Epoch 17/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.7104\n",
            "Epoch 18/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.7149\n",
            "Epoch 19/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.7149\n",
            "Epoch 20/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.7149\n",
            "Epoch 21/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.7160\n",
            "Epoch 22/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.7138\n",
            "Epoch 23/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.7194\n",
            "Epoch 24/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.7183\n",
            "Epoch 25/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.7149\n",
            "Epoch 26/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2824 - accuracy: 0.7172\n",
            "Epoch 27/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2813 - accuracy: 0.7183\n",
            "Epoch 28/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.7250\n",
            "Epoch 29/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.7228\n",
            "Epoch 30/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.7329\n",
            "Epoch 31/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.7329\n",
            "Epoch 32/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.7340\n",
            "Epoch 33/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.7351\n",
            "Epoch 34/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.7329\n",
            "Epoch 35/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.7385\n",
            "Epoch 36/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.7419\n",
            "Epoch 37/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.7452\n",
            "Epoch 38/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.7464\n",
            "Epoch 39/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.7374\n",
            "Epoch 40/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.7407\n",
            "Epoch 41/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.7340\n",
            "Epoch 42/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.7407\n",
            "Epoch 43/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.7587\n",
            "Epoch 44/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.7576\n",
            "Epoch 45/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.7565\n",
            "Epoch 46/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.7565\n",
            "Epoch 47/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.7688\n",
            "Epoch 48/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.7744\n",
            "Epoch 49/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.7823\n",
            "Epoch 50/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.7856\n",
            "Epoch 51/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.7688\n",
            "Epoch 52/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.7845\n",
            "Epoch 53/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.7879\n",
            "Epoch 54/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.7980\n",
            "Epoch 55/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.7935\n",
            "Epoch 56/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.7946\n",
            "Epoch 57/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.7991\n",
            "Epoch 58/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.7912\n",
            "Epoch 59/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.7969\n",
            "Epoch 60/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.8070\n",
            "Epoch 61/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.8126\n",
            "Epoch 62/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.8081\n",
            "Epoch 63/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.8070\n",
            "Epoch 64/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.8025\n",
            "Epoch 65/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.8013\n",
            "Epoch 66/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.8013\n",
            "Epoch 67/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.8126\n",
            "Epoch 68/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.8103\n",
            "Epoch 69/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.8137\n",
            "Epoch 70/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.8182\n",
            "Epoch 71/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.8171\n",
            "Epoch 72/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.8036\n",
            "Epoch 73/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.8159\n",
            "Epoch 74/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.8159\n",
            "Epoch 75/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.8227\n",
            "Epoch 76/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.8193\n",
            "Epoch 77/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.8215\n",
            "Epoch 78/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.8193\n",
            "Epoch 79/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.8238\n",
            "Epoch 80/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.8137\n",
            "Epoch 81/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.8260\n",
            "Epoch 82/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8272\n",
            "Epoch 83/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.8092\n",
            "Epoch 84/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.8182\n",
            "Epoch 85/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.8260\n",
            "Epoch 86/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.8272\n",
            "Epoch 87/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.8272\n",
            "Epoch 88/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.8272\n",
            "Epoch 89/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.8249\n",
            "Epoch 90/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.8272\n",
            "Epoch 91/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.8294\n",
            "Epoch 92/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8227\n",
            "Epoch 93/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8260\n",
            "Epoch 94/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.8227\n",
            "Epoch 95/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.8294\n",
            "Epoch 96/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.8249\n",
            "Epoch 97/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.8283\n",
            "Epoch 98/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.8272\n",
            "Epoch 99/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.8215\n",
            "Epoch 100/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.8272\n",
            "Epoch 101/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8305\n",
            "Epoch 102/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8305\n",
            "Epoch 103/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.8204\n",
            "Epoch 104/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.8193\n",
            "Epoch 105/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8272\n",
            "Epoch 106/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.8260\n",
            "Epoch 107/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.8294\n",
            "Epoch 108/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.8305\n",
            "Epoch 109/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.8316\n",
            "Epoch 110/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8328\n",
            "Epoch 111/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.8193\n",
            "Epoch 112/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.8283\n",
            "Epoch 113/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.8294\n",
            "Epoch 114/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.8249\n",
            "Epoch 115/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.8294\n",
            "Epoch 116/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.8305\n",
            "Epoch 117/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.8283\n",
            "Epoch 118/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.8260\n",
            "Epoch 119/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.8294\n",
            "Epoch 120/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.8272\n",
            "Epoch 121/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8283\n",
            "Epoch 122/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.8305\n",
            "Epoch 123/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.8204\n",
            "Epoch 124/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.8249\n",
            "Epoch 125/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.8294\n",
            "Epoch 126/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8316\n",
            "Epoch 127/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.8328\n",
            "Epoch 128/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.8305\n",
            "Epoch 129/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8305\n",
            "Epoch 130/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.8328\n",
            "Epoch 131/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8283\n",
            "Epoch 132/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.8249\n",
            "Epoch 133/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8249\n",
            "Epoch 134/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.8316\n",
            "Epoch 135/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.8260\n",
            "Epoch 136/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.8316\n",
            "Epoch 137/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.8305\n",
            "Epoch 138/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8305\n",
            "Epoch 139/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8249\n",
            "Epoch 140/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8294\n",
            "Epoch 141/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.8328\n",
            "Epoch 142/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.8294\n",
            "Epoch 143/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.8305\n",
            "Epoch 144/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.8316\n",
            "Epoch 145/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.8328\n",
            "Epoch 146/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.8260\n",
            "Epoch 147/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.8305\n",
            "Epoch 148/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8272\n",
            "Epoch 149/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.8305\n",
            "Epoch 150/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.8316\n",
            "Epoch 151/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.8339\n",
            "Epoch 152/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.8305\n",
            "Epoch 153/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.8305\n",
            "Epoch 154/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8294\n",
            "Epoch 155/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.8316\n",
            "Epoch 156/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.8316\n",
            "Epoch 157/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.8316\n",
            "Epoch 158/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.8328\n",
            "Epoch 159/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.8294\n",
            "Epoch 160/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.8305\n",
            "Epoch 161/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.8305\n",
            "Epoch 162/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8283\n",
            "Epoch 163/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.8328\n",
            "Epoch 164/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.8294\n",
            "Epoch 165/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.8294\n",
            "Epoch 166/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.8294\n",
            "Epoch 167/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.8227\n",
            "Epoch 168/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.8193\n",
            "Epoch 169/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.8013\n",
            "Epoch 170/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.8114\n",
            "Epoch 171/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.8227\n",
            "Epoch 172/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.8238\n",
            "Epoch 173/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.8316\n",
            "Epoch 174/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.8328\n",
            "Epoch 175/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.8316\n",
            "Epoch 176/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.8305\n",
            "Epoch 177/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.8316\n",
            "Epoch 178/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.8316\n",
            "Epoch 179/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.8294\n",
            "Epoch 180/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.8328\n",
            "Epoch 181/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.8305\n",
            "Epoch 182/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.8328\n",
            "Epoch 183/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.8339\n",
            "Epoch 184/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.8283\n",
            "Epoch 185/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.8316\n",
            "Epoch 186/200\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.8328\n",
            "Epoch 187/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.8316\n",
            "Epoch 188/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.8339\n",
            "Epoch 189/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.8328\n",
            "Epoch 190/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.8305\n",
            "Epoch 191/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.8316\n",
            "Epoch 192/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.8316\n",
            "Epoch 193/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.8126\n",
            "Epoch 194/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.8260\n",
            "Epoch 195/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.8305\n",
            "Epoch 196/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.8294\n",
            "Epoch 197/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.8316\n",
            "Epoch 198/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.8316\n",
            "Epoch 199/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.8316\n",
            "Epoch 200/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.8316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ELmWTEJvHPIl",
        "outputId": "dd5cebd8-a135-4d3d-c91f-9450717ccc60"
      },
      "source": [
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['accuracy'])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-lyEmlVHPra",
        "outputId": "03512ee7-70fa-47c7-9124-49951f6d2235"
      },
      "source": [
        "model.evaluate(X_test,Y_test)\n",
        "pred=[[1,0,34,1,0,54.3900,2]]\n",
        "y_pred=np.argmax(model.predict(pred))\n",
        "print(y_pred)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9234\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4m-F0GDTRYn"
      },
      "source": [
        "X_test=np.array(X_test)\n",
        "Y_test=np.array(Y_test)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R179DsJWEjkM"
      },
      "source": [
        "class KNN:\n",
        "  \n",
        "  def __init__(self,k):\n",
        "    self.k=k\n",
        "\n",
        "  def fit(self,X_train,Y_train):\n",
        "    self.X_train=X_train\n",
        "    self.Y_train=Y_train\n",
        "\n",
        "    self.num_of_class=len(np.unique(Y_train))\n",
        "    #print(self.num_of_class)\n",
        "\n",
        "  def nearNeighbors(self,X_test):\n",
        "    distance=np.sqrt(np.sum((X_test-self.X_train)**2,axis=1))\n",
        "    near_neighbors=np.argsort(distance)[0:self.k]\n",
        "    return near_neighbors\n",
        "\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    near_neighbors=self.nearNeighbors(X_test)\n",
        "    #print(near_neighbors)\n",
        "    y_pred=np.argmax(np.bincount(self.Y_train[near_neighbors])) \n",
        "    return y_pred\n",
        "\n",
        "  def evaluate(self,X_test,Y_test):\n",
        "    num_of_correct_pred=0\n",
        "    self.X_test=X_test\n",
        "    self.Y_test=Y_test\n",
        "    y=[]\n",
        "    for i in range(X_test.shape[0]):\n",
        "      #print(X_test.shape[0],X_test[i])\n",
        "      y.append(self.predict(X_test[i,:]))\n",
        "    for i in range(len(y)):\n",
        "      if(Y_test[i]==y[i]):\n",
        "        num_of_correct_pred +=1\n",
        "        #print(num_of_correct_pred)\n",
        "    return (num_of_correct_pred /len(Y_test))*100"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmnyGqgwEpzl",
        "outputId": "b07c86b6-165d-4ac5-c3fc-ad7337f25551"
      },
      "source": [
        "print(Y_test.shape)\n",
        "print(Y_train.shape)\n",
        "Y_train=Y_train.reshape(-1)\n",
        "Y_test=Y_test.reshape(-1)\n",
        "print(Y_train.shape,Y_test.shape)\n",
        "\n",
        "knn=KNN(5)\n",
        "knn.fit(X_train,Y_train)\n",
        "accuracy=knn.evaluate(X_test,Y_test)\n",
        "print(\"accuracy :\",accuracy)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(418, 1)\n",
            "(891, 1)\n",
            "(891,) (418,)\n",
            "accuracy : 65.55023923444976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EGNWAiEwzA"
      },
      "source": [
        "class Adaline:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self,X_train,Y_train):\n",
        "    self.w=np.matmul(np.linalg.inv(np.matmul(X_train.T,X_train)),np.matmul(X_train.T,Y_train)) \n",
        "    \n",
        "  def predict(self,X_test):\n",
        "    y_pred=[]\n",
        "\n",
        "    Y_pred=np.matmul(X_test,self.w)  \n",
        "    for i in range(len(Y_pred)):\n",
        "      if((Y_pred[i]-Y_test[i])**2)<= 0.5:\n",
        "        y_pred.append(0)\n",
        "      elif((Y_pred[i]-Y_test[i])**2)> 0.5:\n",
        "        y_pred.append(1)\n",
        "    return y_pred    \n",
        "\n",
        "  def evaluate(self,y_pred,Y_test):\n",
        "    num_of_correct_pred=0\n",
        "    y=[]\n",
        "\n",
        "    for i in range(len(Y_test)):\n",
        "      if(Y_test[i]==y_pred[i]):\n",
        "        num_of_correct_pred+=1\n",
        "    accuracy=(num_of_correct_pred/len(Y_test))*100\n",
        "    return accuracy"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcJwSBQME4JL",
        "outputId": "202bda7e-a620-45d7-af8c-332f92fb9ce8"
      },
      "source": [
        "adaline=Adaline()\n",
        "adaline.fit(X_train,Y_train)\n",
        "y_pred=adaline.predict(X_test)\n",
        "accuracy=adaline.evaluate(y_pred,Y_test)\n",
        "print(\"accuracy =\",accuracy)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 62.67942583732058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18JN3JqrFCX4"
      },
      "source": [
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self,X_train,Y_train):\n",
        "\n",
        "    errors=[]\n",
        "    iteration=[]\n",
        "    lr=0.001\n",
        "    \n",
        "    N=X_train.shape[0]\n",
        "    self.w=np.random.rand(7,1)\n",
        "    self.b=np.random.rand(1,1)\n",
        "\n",
        "    for j in range(N):\n",
        "        \n",
        "      y_pred=np.matmul(X_train[j],self.w)+self.b\n",
        "      e=Y_train[j]-y_pred\n",
        "      \n",
        "      self.w+=(lr*(X_train[j].T*e).T)\n",
        "      self.b+=lr*e\n",
        "      \n",
        "       \n",
        "      Y_pred=np.matmul(X_train,self.w)+self.b\n",
        "     \n",
        "\n",
        "  def predict(self,X_test):\n",
        "    Y_test_pred=np.matmul(X_train,self.w)+self.b\n",
        "    Y_test_pred[Y_test_pred>0.5]=1\n",
        "    Y_test_pred[Y_test_pred<=0.5]=0\n",
        "    #print(Y_test_pred)\n",
        "    return Y_test_pred\n",
        "\n",
        " \n",
        "  def evaluate(self,X_train,X_test):\n",
        "    Y_test_pred=np.matmul(X_test,self.w)+self.b\n",
        "    Y_test_pred[Y_test_pred>0.5]=1\n",
        "    Y_test_pred[Y_test_pred<=0.5]=0\n",
        "\n",
        "    num_of_correct_pred=0\n",
        "\n",
        "    for i in range(len(Y_test)):\n",
        "      if(Y_test_pred[i]==Y_test[i]):\n",
        "        num_of_correct_pred+=1\n",
        "    accuracy=num_of_correct_pred/len(Y_test)*100\n",
        "    return accuracy"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqU1sUB4FU50",
        "outputId": "1380536a-5f12-4ddd-d102-654e9a9f5d92"
      },
      "source": [
        "perceptron=Perceptron()\n",
        "perceptron.fit(X_train,Y_train)\n",
        "Y_test_pred=perceptron.predict(X_test)\n",
        "\n",
        "accuracy=perceptron.evaluate(X_train,X_test)\n",
        "print('accuracy ',accuracy)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy  61.961722488038276\n"
          ]
        }
      ]
    }
  ]
}